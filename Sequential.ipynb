{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae74d61b-c3cc-4a55-9fc9-e69fb3934d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1194 images belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harini\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\Harini\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "import time\n",
    "\n",
    "# 1. Organize the dataset directory path\n",
    "dataset_path = 'E:/Harini/SLIIT/4 year/RP/images'  # Replace with your dataset path\n",
    "\n",
    "# Function to extract RGB average values from the image\n",
    "def extract_rgb_features(img_path):\n",
    "    # Load image and resize to 224x224 for CNN\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)  # Convert image to numpy array\n",
    "    \n",
    "    # Normalize pixel values to [0, 1]\n",
    "    img_array = img_array / 255.0\n",
    "    \n",
    "    # Calculate the average RGB values\n",
    "    avg_rgb = np.mean(img_array, axis=(0, 1))  # Average across width and height\n",
    "    return avg_rgb\n",
    "\n",
    "# 2. Preprocessing function for CNN\n",
    "def prepare_image(img_path):\n",
    "    # Load image and resize it to 224x224 for CNN\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array = img_array / 255.0  # Normalize pixel values to [0, 1]\n",
    "    return img_array\n",
    "\n",
    "# 3. Set up the ImageDataGenerator for training\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values to [0, 1]\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Load images from the dataset directory (subfolders are used as class labels)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Multi-class classification\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# 4. Build the custom CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layers\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten the output of the convolutional layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add dense layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Dropout to prevent overfitting\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Dropout to prevent overfitting\n",
    "model.add(Dense(4, activation='softmax'))  # 4 classes: not_mature, partially_mature, mature, rotten\n",
    "\n",
    "# 5. Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 6. Custom data generator for feeding RGB features (this step is optional, use ImageDataGenerator if you only need to feed images)\n",
    "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, directory, batch_size, target_size, class_mode):\n",
    "        self.directory = directory\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size = target_size\n",
    "        self.class_mode = class_mode\n",
    "        self.classes = os.listdir(directory)\n",
    "        self.class_indices = {c: idx for idx, c in enumerate(self.classes)}\n",
    "        self.filenames = []\n",
    "        \n",
    "        # Gather all image filenames\n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(directory, class_name)\n",
    "            for filename in os.listdir(class_dir):\n",
    "                self.filenames.append((class_name, filename))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.filenames) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_filenames = self.filenames[index * self.batch_size: (index + 1) * self.batch_size]\n",
    "        \n",
    "        # Prepare the batch\n",
    "        images = []\n",
    "        rgb_features = []\n",
    "        labels = []\n",
    "        \n",
    "        for class_name, filename in batch_filenames:\n",
    "            img_path = os.path.join(self.directory, class_name, filename)\n",
    "            rgb_feature = extract_rgb_features(img_path)\n",
    "            img_array = prepare_image(img_path)\n",
    "            \n",
    "            images.append(img_array)\n",
    "            rgb_features.append(rgb_feature)\n",
    "            labels.append(self.class_indices[class_name])\n",
    "        \n",
    "        # Convert lists to numpy arrays\n",
    "        images = np.vstack(images)\n",
    "        rgb_features = np.vstack(rgb_features)\n",
    "        labels = to_categorical(labels, num_classes=4)\n",
    "        \n",
    "        return images, labels\n",
    "\n",
    "# 7. Train the model using the custom generator\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "start_time = time.time()\n",
    "train_generator = CustomDataGenerator(dataset_path, batch_size=batch_size, target_size=(224, 224), class_mode='categorical')\n",
    "history = model.fit(train_generator, epochs=epochs)\n",
    "\n",
    "# 8. Save the model\n",
    "model.save('papaya_maturity_model_with_rgb_cnn.h5')\n",
    "print(\"Model training complete and saved!\")\n",
    "\n",
    "# 9. Get the model version and training details\n",
    "model_version = model.name\n",
    "num_classes = len(train_generator.classes)\n",
    "dataset_size = len(train_generator.filenames)\n",
    "input_size = (224, 224, 3)\n",
    "avg_accuracy = np.mean(history.history['accuracy'])\n",
    "avg_loss = np.mean(history.history['loss'])\n",
    "avg_confidence = np.mean(history.history['accuracy']) * 100\n",
    "\n",
    "# Calculate batch processing time\n",
    "batch_processing_time = (time.time() - start_time) / (len(train_generator) * epochs)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Model Version: {model_version}\")\n",
    "print(f\"Number of Classes: {num_classes}\")\n",
    "print(f\"Dataset Size: {dataset_size} images\")\n",
    "print(f\"Number of Epochs: {epochs}\")\n",
    "print(f\"Batch Size: {batch_size}\")\n",
    "print(f\"Input Size: {input_size}\")\n",
    "print(f\"Average Confidence: {avg_confidence:.2f}%\")\n",
    "print(f\"Average Accuracy: {avg_accuracy * 100:.2f}%\")\n",
    "print(f\"Average Loss: {avg_loss:.4f}\")\n",
    "print(f\"Batch Processing Time (seconds per batch): {batch_processing_time:.4f}\")\n",
    "\n",
    "# Provide the path to your test image\n",
    "test_image_path = 'E:/Harini/SLIIT/4 year/RP/images/mature/Mature_003.jpg'  # Replace with the path to the test image\n",
    "\n",
    "# Preprocess the image\n",
    "test_image = prepare_image(test_image_path)  # Use the correct function name\n",
    "\n",
    "# Predict the class\n",
    "prediction = model.predict(test_image)\n",
    "\n",
    "# Get the predicted class index (highest probability)\n",
    "predicted_class_index = np.argmax(prediction, axis=1)[0]\n",
    "\n",
    "# Mapping of class indices to class labels\n",
    "class_labels = ['mature', 'not_mature', 'partially_mature', 'rotten']\n",
    "\n",
    "# Get the predicted class label\n",
    "predicted_class = class_labels[predicted_class_index]\n",
    "\n",
    "# Display the prediction result\n",
    "print(f'The model predicts that the papaya is: {predicted_class}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6524f325-3925-4744-b3cb-b18be1573932",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
